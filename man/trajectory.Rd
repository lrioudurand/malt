% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trajectory.R
\name{trajectory}
\alias{trajectory}
\title{trajectory}
\usage{
trajectory(init, U, grad, g, h, L)
}
\arguments{
\item{init}{Real vector. Initial values for the Langevin trajectory.}

\item{U}{A potential function to return the log-density of the distribution to be sampled from, up to an additive constant. It should input a real vector of the same length as init and output a scalar.}

\item{grad}{A function to return the gradient of the potential. It should input and output a real vector of the same length as init.}

\item{g}{Non-negative real number. The friction, a.k.a damping parameter. The choice g=0 boils down to Hamiltonian Monte Carlo.}

\item{h}{Positive real number. The time step.}

\item{L}{Positive integer. The number of steps per trajectory. The choice L=1 boils down to the Metropolis Adjusted Langevin Algorithm.}
}
\value{
Returns a list with the following objects:
\item{path}{a matrix whose rows are the successive steps of the trajectory.}
\item{draw}{a vector containing the output of the trajectory.}
\item{num_error}{a vector containing the cumulative numerical errors along the path. The numerical error is measured by the energy difference incurred by the leapfrog integrator.}
}
\description{
Draws a numerical Langevin trajectory with target density \deqn{\Pi(x)\propto e^{-U(x)}}{Pi(x)=exp(-U(x))/C} Given a potential function \eqn{U}{U} and its gradient evaluation, draws a trajectory and computes its numerical error. The trajectory drawn corresponds to the proposal in the sampling algorithm: Metropolis Adjusted Langevin Trajectories (Riou-Durand and Vogrinc 2022). Details available at: https://arxiv.org/abs/2202.13230.
}
\examples{
d=50
sigma=((d:1)/d)^(1/2)
init=rnorm(d)*sigma
U=function(x){sum(0.5*x^2/sigma^2)}
grad=function(x){x/sigma^2}
g=1.5
h=0.20
L=10
trajectory(init,U,grad,g,h,L)
}
